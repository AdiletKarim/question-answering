{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1d764158",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import torch, os\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d85faea3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.35.2-py3-none-any.whl.metadata (123 kB)\n",
      "     ------------------------------------- 123.5/123.5 kB 72.5 kB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (3.0.12)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
      "  Downloading huggingface_hub-0.19.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (2.30.0)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers)\n",
      "  Downloading tokenizers-0.15.0-cp38-none-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.3.1 (from transformers)\n",
      "  Downloading safetensors-0.4.1-cp38-none-win_amd64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (4.66.1)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.16.4->transformers)\n",
      "  Downloading fsspec-2023.12.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (2022.12.7)\n",
      "Downloading transformers-4.35.2-py3-none-any.whl (7.9 MB)\n",
      "   ---------------------------------------- 7.9/7.9 MB 858.1 kB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.19.4-py3-none-any.whl (311 kB)\n",
      "   ---------------------------------------- 311.7/311.7 kB 1.3 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.4.1-cp38-none-win_amd64.whl (277 kB)\n",
      "   ---------------------------------------- 277.7/277.7 kB 1.3 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.15.0-cp38-none-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 2.2/2.2 MB 1.7 MB/s eta 0:00:00\n",
      "Downloading fsspec-2023.12.1-py3-none-any.whl (168 kB)\n",
      "   ---------------------------------------- 168.9/168.9 kB 2.0 MB/s eta 0:00:00\n",
      "Installing collected packages: safetensors, fsspec, huggingface-hub, tokenizers, transformers\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 0.9.0\n",
      "    Uninstalling fsspec-0.9.0:\n",
      "      Successfully uninstalled fsspec-0.9.0\n",
      "Successfully installed fsspec-2023.12.1 huggingface-hub-0.19.4 safetensors-0.4.1 tokenizers-0.15.0 transformers-4.35.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a032626f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e8b08941b8641488724e9903a137c3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/394 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05095dbff73b4928b5bdc8c47e9b9ac6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/1.45M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4501f11371884ae0a9e994f90c743b9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "205af416b2fe4327b540cb5be491215a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/647 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdfa0dd114a3464e96b31cfe6e6f1415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/652M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ce803906a684119aa69cba00fc7af3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/90.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"amandyk/KazakhBERTmulti\")\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"amandyk/KazakhBERTmulti\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "22461188",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(100000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (transform_act_fn): GELUActivation()\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=100000, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0b565239",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(BERT, self).__init__()\n",
    "        self.BERT = model.bert\n",
    "        self.qa_outputs = nn.Linear(in_features=768, out_features=2, bias=True)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask=None, token_type_ids=None):\n",
    "        x = self.BERT(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        x = self.qa_outputs(x.last_hidden_state)\n",
    "        \n",
    "        return {\n",
    "            'start_logits': x[:, :, 0],\n",
    "            'end_logits': x[:, :, 1]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "af9db92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "13da23f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = BERT(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4b93670f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"annotation.csv\")\n",
    "\n",
    "train, val = train_test_split(df, test_size=0.2)\n",
    "\n",
    "train = train.reset_index(drop=True)\n",
    "val = val.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6c401a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data(tokenizer, questions, contexts, max_length=512):\n",
    "    # Convert to lists of strings\n",
    "    questions = [str(q) for q in questions]\n",
    "    contexts = [str(c) for c in contexts]\n",
    "    return tokenizer(questions, contexts, truncation=True, padding='max_length', max_length=max_length)\n",
    "\n",
    "# Assuming your dataframe columns are named 'question' and 'context'\n",
    "# First, ensure they are in the correct format\n",
    "train_questions = train['question'].astype(str)\n",
    "train_contexts = train['context'].astype(str)\n",
    "val_questions = val['question'].astype(str)\n",
    "val_contexts = val['context'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5922c64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the data with specified max_length\n",
    "train_encodings = encode_data(tokenizer, train['question'], train['context'], max_length=512)\n",
    "val_encodings = encode_data(tokenizer, val['question'], val['context'], max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2d4d4ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_token_positions(encodings, df):\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        start_position = encodings.char_to_token(i, df['start_position'].iat[i])\n",
    "        end_position = encodings.char_to_token(i, df['end_position'].iat[i])\n",
    "\n",
    "        # Fallback in case the start or end position is None\n",
    "        if start_position is None:\n",
    "            start_position = 0\n",
    "        if end_position is None:\n",
    "            end_position = start_position\n",
    "\n",
    "        start_positions.append(start_position)\n",
    "        end_positions.append(end_position)\n",
    "\n",
    "    encodings.update({\n",
    "        'start_positions': start_positions,\n",
    "        'end_positions': end_positions\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "85397512",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_token_positions(train_encodings, train)\n",
    "add_token_positions(val_encodings, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3d148b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SquadDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "        \n",
    "    def __len__(self, ):\n",
    "        return len(self.encodings.input_ids)\n",
    "    \n",
    "    def __getitem__(self, x):\n",
    "        return {key: torch.tensor(val[x]) for key, val in self.encodings.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e9fd5d8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vals = next(iter(SquadDataset(train_encodings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0da4754e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SquadDataset(train_encodings)\n",
    "val_dataset = SquadDataset(val_encodings)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0b3ca6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model_name, epoch, prev_loss, current_loss, model, tokenizer, optimizer):\n",
    "    if prev_loss > current_loss:\n",
    "        torch.save({\n",
    "            \"epoch\": epoch,\n",
    "            \"model\": model.state_dict(),\n",
    "            \"tokenizer\": \"best_BERT_tokenizer.pth\",\n",
    "            \"optimizer\": optimizer.state_dict(),\n",
    "            \"loss\": current_loss,\n",
    "        }, f\"models/best_{model_name}.pt\") # create models folder before! \n",
    "        print(\"The best model was saved!\")\n",
    "        prev_loss = current_loss\n",
    "#\n",
    "    \n",
    "    torch.save({\n",
    "            \"epoch\": epoch,\n",
    "            \"model\": model.state_dict(),\n",
    "            \"tokenizer\": \"last_BERT_tokenizer.pth\",\n",
    "            \"optimizer\": optimizer.state_dict(),\n",
    "            \"loss\": current_loss,\n",
    "        }, f\"models/last_{model_name}.pt\")\n",
    "    return prev_loss\n",
    "\n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4faca1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CrossNetropyLoss(nn.Module):\n",
    "#     def __init__(self,):\n",
    "#         super(CrossNetropyLoss, self).__init__()\n",
    "#         self.entropy = nn.CrossEntropyLoss() \n",
    "    \n",
    "#     def forward(self, x, start, end):\n",
    "#         return self.entropy(x['start_logits'], start) + self.entropy(x['end_logits'], end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d8b1a0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropyLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CrossEntropyLoss, self).__init__()\n",
    "        self.entropy = nn.CrossEntropyLoss() \n",
    "    \n",
    "    def forward(self, model_output, start_positions, end_positions):\n",
    "        start_logits, end_logits = model_output['start_logits'], model_output['end_logits']\n",
    "        start_loss = self.entropy(start_logits, start_positions)\n",
    "        end_loss = self.entropy(end_logits, end_positions)\n",
    "        total_loss = (start_loss + end_loss) / 2  # Averaging the two losses\n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5c161bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BERT(\n",
       "  (BERT): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(100000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d3e9d905",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model.train()\n",
    "Model.to(device)\n",
    "optim = torch.optim.AdamW(Model.parameters(), lr=5e-5)\n",
    "criterion = CrossNetropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "05d65404",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|█████████████████████████████████████████████████████████| 121/121 [1:29:51<00:00, 44.56s/it, loss=0.811]\n",
      "Epoch 0: 100%|█████████████████████████████████████████████████████████████| 31/31 [07:42<00:00, 14.93s/it, loss=0.605]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model was saved!\n",
      "Epoch: 0 | Training loss 2.36106879528889 | Validation loss 1.9836411360771424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   7%|███▉                                                        | 8/121 [05:14<1:14:04, 39.33s/it, loss=1.87]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-125-6c7a4fff3e32>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mend_positions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'end_positions'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_positions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_positions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-73-f79d12cb4bff>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBERT\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqa_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlast_hidden_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1011\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1012\u001b[0m         )\n\u001b[1;32m-> 1013\u001b[1;33m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[0;32m   1014\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1015\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    605\u001b[0m                 )\n\u001b[0;32m    606\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 607\u001b[1;33m                 layer_outputs = layer_module(\n\u001b[0m\u001b[0;32m    608\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    495\u001b[0m         \u001b[1;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 497\u001b[1;33m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[0;32m    498\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    425\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m     ) -> Tuple[torch.Tensor]:\n\u001b[1;32m--> 427\u001b[1;33m         self_outputs = self.self(\n\u001b[0m\u001b[0;32m    428\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m         \u001b[1;31m# Normalize the attention scores to probabilities.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m         \u001b[0mattention_probs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattention_scores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m         \u001b[1;31m# This is actually dropping out entire tokens to attend to, which might\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36msoftmax\u001b[1;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[0;32m   1839\u001b[0m         \u001b[0mdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"softmax\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1840\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1841\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1842\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1843\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs, prev_loss = 100, torch.inf\n",
    "train_loss, val_loss = [], []\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    loop = tqdm(train_loader)\n",
    "    loss_list, count = 0, 0\n",
    "    for batch in loop:\n",
    "        optim.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_positions = batch['start_positions'].to(device)\n",
    "        end_positions = batch['end_positions'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        loss = criterion(outputs, start_positions, end_positions)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        loss_list += loss.item()\n",
    "        count += 1\n",
    "        \n",
    "        loop.set_description(f\"Epoch {epoch}\")\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "    \n",
    "    loss = loss_list/count\n",
    "    train_loss.append(loss)\n",
    "    model.eval()\n",
    "    @torch.no_grad()\n",
    "    def validation():\n",
    "        loop = tqdm(val_loader)\n",
    "        loss_list, count = 0, 0\n",
    "        for batch in loop:            \n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            start_positions = batch['start_positions'].to(device)\n",
    "            end_positions = batch['end_positions'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            \n",
    "            loss = criterion(outputs, start_positions, end_positions)\n",
    "            loss_list += loss.item()\n",
    "            count += 1\n",
    "            \n",
    "            loop.set_description(f\"Epoch {epoch}\")\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "\n",
    "        return loss_list / count\n",
    "    v_loss = validation()\n",
    "    val_loss.append(v_loss)    \n",
    "    prev_loss = save_model(\"BERT\", epoch, prev_loss, v_loss, model, tokenizer, optim)\n",
    "    print(f\"Epoch: {epoch} | Training loss {loss} | Validation loss {v_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1beb8a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "2087660e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"epochs\": range(0, 1),\n",
    "    \"train_loss\": train_loss,\n",
    "    \"val_loss\": val_loss\n",
    "})\n",
    "df.to_csv(\"losses_1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "cc34dde7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epochs</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.361069</td>\n",
       "      <td>1.983641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epochs  train_loss  val_loss\n",
       "0       0    2.361069  1.983641"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c3618a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "70f57122",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample data (replace with your actual data)\n",
    "epochs = [1]  # X-axis (epochs)\n",
    "train_loss = [2.361069]  # Training loss\n",
    "val_loss = [1.983641]  # Validation loss\n",
    "\n",
    "# Create a plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, train_loss, label='Training Loss', marker='o')\n",
    "plt.plot(epochs, val_loss, label='Validation Loss', marker='o')\n",
    "\n",
    "# Add labels, title, legend, etc.\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot or save it to a file\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "8915dd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"models/best_BERT.pt\")['model'])\n",
    "model.cpu();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "cfb274b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the first 1200 rows from the CSV file\n",
    "train = pd.read_csv(\"annotation.csv\", sep=',', error_bad_lines=False, nrows=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "fe175823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the range of rows you want to read (from 1200 to 1500)\n",
    "start_row = 1201\n",
    "end_row = 1500\n",
    "\n",
    "# Calculate the number of rows to read\n",
    "num_rows_to_read = end_row - start_row\n",
    "\n",
    "# Read the specified range of rows from the CSV file\n",
    "val = pd.read_csv(\"annotation.csv\", sep=',', error_bad_lines=False, skiprows=range(1, start_row), nrows=num_rows_to_read)\n",
    "\n",
    "# Now, the 'train' DataFrame contains rows 1200 to 1500 from the CSV file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "f7926d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your dataframe columns are named 'question' and 'context'\n",
    "# First, ensure they are in the correct format\n",
    "train_questions = train['question'].astype(str)\n",
    "train_contexts = train['context'].astype(str)\n",
    "val_questions = val['question'].astype(str)\n",
    "val_contexts = val['context'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "710453e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the data with specified max_length\n",
    "train_encodings = encode_data(tokenizer, train['question'], train['context'], max_length=512)\n",
    "val_encodings = encode_data(tokenizer, val['question'], val['context'], max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "3cf06e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_token_positions(train_encodings, train)\n",
    "add_token_positions(val_encodings, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "7a40938e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SquadDataset(train_encodings)\n",
    "val_dataset = SquadDataset(val_encodings)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "8dbd4c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [08:01<00:00, 16.03s/it]\n"
     ]
    }
   ],
   "source": [
    "start_positions_, end_positions_ = [], []\n",
    "target_start_positions_, target_end_positions_ = [], []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    loop = tqdm(val_loader)\n",
    "    loss_list, count = 0, 0\n",
    "    for batch in loop:            \n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_positions = batch['start_positions'].to(device)\n",
    "        end_positions = batch['end_positions'].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        for start in outputs['start_logits'].argmax(dim=1):\n",
    "            start_positions_.append(start.cpu().item())\n",
    "        for end in outputs['end_logits'].argmax(dim=1):\n",
    "            end_positions_.append(end.cpu().item())\n",
    "            \n",
    "        for start in start_positions:\n",
    "            target_start_positions_.append(start.cpu().item())\n",
    "        for end in end_positions:\n",
    "            target_end_positions_.append(end.cpu().item())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "a8bf4c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_results = pd.DataFrame({\n",
    "    \"predicted_start_positions\": start_positions_,\n",
    "    \"predicted_end_posiitons\": end_positions_,\n",
    "    \"target_start_positions\": target_start_positions_,\n",
    "    \"target_end_positions\": target_end_positions_,\n",
    "})\n",
    "# validation_results.to_csv(\"validation_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "8ef33ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "3770feff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8561872909698997"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(validation_results['predicted_start_positions'], validation_results['target_start_positions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "8e3d9e77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8461538461538461"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(validation_results['predicted_end_posiitons'], validation_results['target_end_positions'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
